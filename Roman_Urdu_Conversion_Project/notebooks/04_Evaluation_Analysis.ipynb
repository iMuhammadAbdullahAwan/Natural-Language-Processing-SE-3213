{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d7e980",
   "metadata": {},
   "source": [
    "# Evaluation and Analysis\n",
    "## Roman Urdu to Urdu Script Conversion Project\n",
    "\n",
    "This notebook covers Step 6, 7 & 8 of our methodology:\n",
    "- Model Evaluation and Comparison\n",
    "- Human Evaluation\n",
    "- Final Analysis and Reporting\n",
    "\n",
    "### Objectives:\n",
    "1. Compare all model performances\n",
    "2. Conduct human evaluation\n",
    "3. Analyze error patterns\n",
    "4. Summarize findings and recommendations\n",
    "5. Prepare final project report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path('../')\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from evaluation.evaluate import compare_models\n",
    "from evaluation.human_evaluation import HumanEvaluation\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6d0a8",
   "metadata": {},
   "source": [
    "## 1. Automated Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41eba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models using evaluation framework\n",
    "results = compare_models()\n",
    "\n",
    "print(\"Model Comparison Results:\")\n",
    "print(\"=\" * 40)\n",
    "for model, metrics in results['metrics'].items():\n",
    "    print(f\"{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "metrics_df = pd.DataFrame(results['metrics']).T\n",
    "metrics_df.plot(kind='bar', figsize=(15, 8))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde56d7",
   "metadata": {},
   "source": [
    "## 2. Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run human evaluation interface\n",
    "human_eval = HumanEvaluation()\n",
    "human_eval.run_gui()  # Launches GUI for human assessment\n",
    "\n",
    "# After evaluation, load results\n",
    "human_results = human_eval.load_results()\n",
    "\n",
    "print(\"Human Evaluation Results:\")\n",
    "print(\"=\" * 40)\n",
    "print(human_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee8aa7",
   "metadata": {},
   "source": [
    "## 3. Error Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze error patterns\n",
    "error_df = pd.DataFrame(results['error_analysis'])\n",
    "print(\"Error Analysis Summary:\")\n",
    "print(error_df.head())\n",
    "\n",
    "# Visualize error types\n",
    "error_types = error_df['error_type'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "error_types.plot(kind='bar', color='lightcoral')\n",
    "plt.title('Error Type Distribution')\n",
    "plt.xlabel('Error Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761eaba",
   "metadata": {},
   "source": [
    "## 4. Final Project Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88416817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize findings\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "for model, metrics in results['metrics'].items():\n",
    "    print(f\"{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Human Evaluation:\")\n",
    "print(human_results)\n",
    "\n",
    "print(\"Error Analysis:\")\n",
    "print(error_df.describe())\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"1. Expand dictionary and training data\")\n",
    "print(\"2. Use hybrid approaches for best results\")\n",
    "print(\"3. Implement context-aware models\")\n",
    "print(\"4. Conduct further human evaluation studies\")\n",
    "print(\"5. Deploy and test in real-world scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3adcb6",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Project Achievements:\n",
    "- Developed dictionary-based, ML-based, and deep learning models for Roman Urdu to Urdu conversion\n",
    "- Created comprehensive evaluation framework\n",
    "- Conducted human evaluation\n",
    "- Analyzed error patterns and model strengths/weaknesses\n",
    "- Provided actionable recommendations for future work\n",
    "\n",
    "### Next Steps:\n",
    "- Expand data and dictionary\n",
    "- Implement advanced deep learning models\n",
    "- Develop hybrid and ensemble systems\n",
    "- Deploy for real-world usage and feedback\n",
    "\n",
    "### Thank You!\n",
    "\n",
    "For questions or further collaboration, contact the project team."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
